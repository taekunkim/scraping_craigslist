{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests                      # fetches html\n",
    "from bs4 import BeautifulSoup        # helps extract data from the html \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the header needed when requesting for html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = ({'User-Agent':      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36',\n",
    "            'Accept-Language': 'en-US, en;q=0.5'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the url of Craigslist\n",
    "In this case, I added `&s=` at the end of the url so that we can later add `int` values to access different page numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://sandiego.craigslist.org/search/sss?query=desk+chair&sort=rel&s='\n",
    "IMG_URL = 'https://images.craigslist.org/{}_300x300.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lists that will store data extracted from html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "prices = []\n",
    "dates = []\n",
    "locations = []\n",
    "urls = []\n",
    "imgs = []\n",
    "ids = []\n",
    "last_seen = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary containing all the lists above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'id':        ids,\n",
    "        'name':      names,\n",
    "        'price':     prices,\n",
    "        'date':      dates,\n",
    "        'location':  locations,\n",
    "        'url':       urls,\n",
    "        'images':    imgs\n",
    "        'last_seen': last_seen}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define all the get functions that will extract meaningful data from html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(post):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves the title of the listing. \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        name = post.find('a', class_ = 'result-title hdrlnk').text\n",
    "\n",
    "    except:\n",
    "        name = np.NaN\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(post):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves the price of the listing. \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        price = int(post.a.text[1:])\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        price = int(post.find('span', class_ = 'result-price').text[1:])\n",
    "\n",
    "    except:\n",
    "        price = np.NaN\n",
    "\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(post):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves the date of which the listing was posted. \n",
    "    \"\"\"\n",
    "    \n",
    "    date = post.find('time')\n",
    "\n",
    "    return date['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(post):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves the location at which the listing can be purchased. \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        location = post.find('span', class_ = 'result-hood').text[2:-1]\n",
    "\n",
    "    except:\n",
    "        location = np.NaN\n",
    "\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(post):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves the Craigslist link in which the listing can be purchased. \n",
    "    \"\"\"\n",
    "    \n",
    "    url = post.a['href']\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ Retrieving images from a lisitng is different from other work\n",
    "\n",
    "Notice that images of the listing has a url source of **base url** + **data-id**.  \n",
    "So, we will be creating image urls after extracting `data-ids`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(post):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves image urls of the listing. \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        anchor_tag = post.find('a', class_ = 'result-image gallery')\n",
    "        image_ids = anchor_tag.get('data-ids').split(',')\n",
    "        product_ids = [image_id[2:] for image_id in image_ids]\n",
    "\n",
    "        images = [IMG_URL.format(product_id) for product_id in product_ids]\n",
    "\n",
    "    except:\n",
    "        images = np.NaN\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(post):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves the ID of the original listing. \n",
    "    \"\"\"\n",
    "\n",
    "    post_id = post.get('data-repost-of')\n",
    "\n",
    "    if isinstance(post_id, int):\n",
    "        return post_id\n",
    "\n",
    "    else:\n",
    "        return post.get('data-pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_seen():\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves the date on which the listing was found the latest. \n",
    "    \"\"\"\n",
    "    \n",
    "    return time.asctime( time.localtime(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function that appends new data to corresponding lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_page(posts):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calls all the functions defined above.\n",
    "    Then, saves data to corresponding lists.\n",
    "    \"\"\"\n",
    "    \n",
    "    for post in posts:\n",
    "        names.append(get_name(post))\n",
    "        prices.append(get_price(post))\n",
    "        dates.append(get_date(post))\n",
    "        locations.append(get_location(post))\n",
    "        urls.append(get_url(post))\n",
    "        imgs.append(get_img(post))\n",
    "        ids.append(get_id(post))\n",
    "        last_seen.append(get_last_seen())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function that collects listing data from all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_all_pages():\n",
    "    n = 0\n",
    "\n",
    "    while True:\n",
    "        url = URL + str(n)\n",
    "        response = requests.get(url, headers = HEADERS)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return 'Cannot access website'\n",
    "\n",
    "        html_soup = BeautifulSoup(response.text, features=\"lxml\")\n",
    "        results = html_soup.find_all('li', class_ = 'result-row')\n",
    "        get_all_page(results)\n",
    "\n",
    "        n += 120\n",
    "        total_count = html_soup.find('span', class_ = 'totalcount').text\n",
    "        if n > int(total_count):\n",
    "            break\n",
    "        time.sleep(randint(1,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve all listing data that is currently posted on Craigslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_all_pages()\n",
    "current = pd.DataFrame(data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine current and past data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past = pd.read_csv('tracking.csv')\n",
    "\n",
    "\"\"\"\n",
    "find common listings and keep the earlier last_seen value\n",
    "\"\"\"\n",
    "\n",
    "cols = ['id', 'name', 'price', 'date', 'location', 'url', 'images']\n",
    "\n",
    "current['id']=current['id'].astype(int)\n",
    "duplicate_old = past.merge(current, how = 'left', on = cols).dropna().drop('last_seen_y', axis = 1)\n",
    "duplicate_old = duplicate_old.rename(columns = {'last_seen_x': 'last_seen'})\n",
    "\n",
    "\"\"\"\n",
    "listing found only in the past\n",
    "\"\"\"\n",
    "\n",
    "past_unique = pd.concat([past, duplicate_old, duplicate_old], sort = False).drop_duplicates(keep = False)\n",
    "\n",
    "\"\"\"\n",
    "combine and export with the correct latest seen dates\n",
    "\"\"\"\n",
    "\n",
    "combined = pd.concat([past_unique, current], sort = False)\n",
    "combined.to_csv('tracking.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
